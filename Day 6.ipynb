{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1888c62d-e5b5-4f5e-a328-dd447a475860",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 4
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "USE CATALOG workspace;\n",
    "USE SCHEMA ecommerce;\n",
    "\n",
    "CREATE VOLUME IF NOT EXISTS workspace.ecommerce.raw;\n",
    "CREATE VOLUME IF NOT EXISTS workspace.ecommerce.bronze;\n",
    "CREATE VOLUME IF NOT EXISTS workspace.ecommerce.silver;\n",
    "CREATE VOLUME IF NOT EXISTS workspace.ecommerce.gold;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2839984-cc9b-49f3-a099-beca4e271b5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# Generate synthetic raw data\n",
    "# -----------------------------\n",
    "data = []\n",
    "\n",
    "event_types = [\"view\", \"cart\", \"purchase\"]\n",
    "\n",
    "for i in range(100):\n",
    "    data.append(Row(\n",
    "        user_id=f\"user_{random.randint(1, 20)}\",\n",
    "        user_session=f\"session_{random.randint(1, 30)}\",\n",
    "        product_id=f\"product_{random.randint(1, 10)}\",\n",
    "        product_name=f\"Product {random.randint(1, 10)}\",\n",
    "        event_type=random.choice(event_types),\n",
    "        price=random.randint(5, 500),\n",
    "        event_time=datetime.now() - timedelta(minutes=random.randint(1, 500))\n",
    "    ))\n",
    "\n",
    "raw_df = spark.createDataFrame(data)\n",
    "\n",
    "# -----------------------------\n",
    "# BRONZE write (append-only)\n",
    "# -----------------------------\n",
    "bronze_path = \"/Volumes/workspace/ecommerce/bronze/events\"\n",
    "\n",
    "bronze_df = raw_df.withColumn(\n",
    "    \"ingestion_ts\", F.current_timestamp()\n",
    ")\n",
    "\n",
    "bronze_df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save(bronze_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23c15f9f-216e-417b-a0d4-e1e90c6e7608",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "bronze_path = \"/Volumes/workspace/ecommerce/bronze/events\"\n",
    "silver_path = \"/Volumes/workspace/ecommerce/silver/events\"\n",
    "\n",
    "bronze_df = spark.read.format(\"delta\").load(bronze_path)\n",
    "\n",
    "silver_df = (\n",
    "    bronze_df\n",
    "    .filter(F.col(\"price\").isNotNull())\n",
    "    .filter((F.col(\"price\") > 0) & (F.col(\"price\") < 10000))\n",
    "    .dropDuplicates([\"user_session\", \"event_time\", \"product_id\"])\n",
    "    .withColumn(\"event_date\", F.to_date(\"event_time\"))\n",
    "    .withColumn(\n",
    "        \"price_tier\",\n",
    "        F.when(F.col(\"price\") < 50, \"budget\")\n",
    "         .when(F.col(\"price\") < 200, \"mid\")\n",
    "         .otherwise(\"premium\")\n",
    "    )\n",
    ")\n",
    "\n",
    "silver_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(silver_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e070f834-f960-4e99-a310-1f0ddf1ac3a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "silver_path = \"/Volumes/workspace/ecommerce/silver/events\"\n",
    "gold_path = \"/Volumes/workspace/ecommerce/gold/product_performance\"\n",
    "\n",
    "silver_df = spark.read.format(\"delta\").load(silver_path)\n",
    "\n",
    "gold_df = (\n",
    "    silver_df\n",
    "    .groupBy(\"product_id\", \"product_name\")\n",
    "    .agg(\n",
    "        F.countDistinct(\n",
    "            F.when(F.col(\"event_type\") == \"view\", F.col(\"user_id\"))\n",
    "        ).alias(\"views\"),\n",
    "        F.countDistinct(\n",
    "            F.when(F.col(\"event_type\") == \"purchase\", F.col(\"user_id\"))\n",
    "        ).alias(\"purchases\"),\n",
    "        F.sum(\n",
    "            F.when(F.col(\"event_type\") == \"purchase\", F.col(\"price\"))\n",
    "        ).alias(\"revenue\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"conversion_rate\",\n",
    "        F.when(F.col(\"views\") > 0,\n",
    "               (F.col(\"purchases\") / F.col(\"views\")) * 100\n",
    "        ).otherwise(0)\n",
    "    )\n",
    ")\n",
    "\n",
    "gold_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(gold_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17403657-0fc8-4967-99d9-8d72a92fca3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5963468763380899,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 6",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}